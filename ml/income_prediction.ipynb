{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "977cc5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from pandas.plotting import scatter_matrix\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, OrdinalEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import seaborn as sb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "469af07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModifiedLabelEncoder(LabelEncoder):\n",
    "\n",
    "    def fit_transform(self, y, *args, **kwargs):\n",
    "        return super().fit_transform(y).reshape(-1, 1)\n",
    "\n",
    "    def transform(self, y, *args, **kwargs):\n",
    "        return super().transform(y).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea1b9c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab5f10e3",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 7, 15, 13)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_names = ['age', 'workclass', 'fnlwgt', 'education', 'education-num', 'marital-status', 'occupation',\n",
    "                'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'hours-per-week', 'native-country',\n",
    "                'class']\n",
    "columns_num = ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', 'hours-per-week']\n",
    "columns_cat = ['workclass', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country'] \n",
    "# dropped education as education-num is present\n",
    "\n",
    "columns_corr_cat = ['marital-status', 'relationship', 'sex']\n",
    "len(columns_num), len(columns_cat), len(column_names), len(columns_num) + len(columns_cat) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3757d80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(directory, file_name, names=None, header=None, skiprows=0):\n",
    "    return pd.read_csv(os.path.join(directory, file_name), names=names, header=header, skiprows=skiprows, skipinitialspace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "200babc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_scores(scores):\n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"Mean:\", scores.mean())\n",
    "    print(\"Standard deviation:\", scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ab41a820",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scoring_using_cross_validation(m, x, y, s='accuracy'):\n",
    "    print(\"************* Start of Cross Validation {} {} *************\".format(s, m))\n",
    "    scores_ = cross_val_score(m, x, y, scoring=\"accuracy\", cv=10)\n",
    "    rmse_scores_ = np.sqrt(scores_)\n",
    "    display_scores(rmse_scores_)\n",
    "    print(\"************* End of Cross Validation {} {}*************\".format(s, m))\n",
    "\n",
    "\n",
    "def print_scores(Y_test, Y_predictions):\n",
    "    print(\"************* {} *************\".format(\"start\"))\n",
    "    mse_ = mean_squared_error(Y_test, Y_predictions)\n",
    "    print(\"mse \", mse_)\n",
    "    acc_ = accuracy_score(Y_test, Y_predictions)\n",
    "    print(\"acc \", acc_)\n",
    "    precision_ = precision_score(Y_test, Y_predictions)\n",
    "    print(\"precision_ \", precision_)\n",
    "    recall_ = recall_score(Y_test, Y_predictions)\n",
    "    print(\"recall_ \", recall_)\n",
    "    f1_score_ = f1_score(Y_test, Y_predictions)\n",
    "    print(\"f1_score_ \", f1_score_)\n",
    "    print(\"****************************************\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "33366691",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_directory = '~/workspace/personal/datasets/income_predictions'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3bbb2455",
   "metadata": {},
   "outputs": [],
   "source": [
    "adult_data_df = load_data(base_directory, 'adult.data', column_names, None, 0)\n",
    "adult_test_df = load_data(base_directory, 'adult.test', names=column_names, skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "df1196d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColumnDropperTransformer(TransformerMixin, BaseEstimator):\n",
    "    def __init__(self, columns):\n",
    "        self.columns = columns\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        return X.drop(self.columns, axis=1)\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "\n",
    "class ColumnUnknownValueTransformer(TransformerMixin, BaseEstimator):\n",
    "    def __init__(self, columns):\n",
    "        self.columns = columns\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        for c in self.columns:\n",
    "            X[c].replace(['?'], 'unknown_{}'.format(c), inplace=True)\n",
    "        return X\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9306d828",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_pipeline = Pipeline([\n",
    "    ('unknown_value_replacer', ColumnUnknownValueTransformer(['workclass', 'occupation', 'native-country'])),\n",
    "    ('dropper', ColumnDropperTransformer(['education']))\n",
    "])\n",
    "\n",
    "adult_data_df = preprocess_pipeline.fit_transform(adult_data_df)\n",
    "adult_test_df = preprocess_pipeline.fit_transform(adult_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "65a8064b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_preprocessor(num_cols, cat_cols):\n",
    "    return ColumnTransformer([\n",
    "        ('one-hot-encoder', OneHotEncoder(handle_unknown=\"ignore\"), cat_cols),\n",
    "        ('standard_scaler', StandardScaler(), num_cols)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6ac17a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "split = ShuffleSplit(n_splits=20, test_size=0.25, random_state=42)\n",
    "train_index, test_index = list(split.split(adult_data_df[columns_num]))[0]\n",
    "\n",
    "train_data_set = adult_data_df.loc[train_index]\n",
    "test_data_set = adult_data_df.loc[test_index]\n",
    "\n",
    "\n",
    "X1 = train_data_set[columns_num].join(train_data_set[columns_cat])\n",
    "X2 = train_data_set[columns_num].join(train_data_set[columns_corr_cat])\n",
    "# print(X1.shape, len(columns_num + columns_cat))\n",
    "# print(X2.shape, len(columns_num + columns_corr_cat))\n",
    "\n",
    "\n",
    "\n",
    "X_train = train_data_set.drop(columns=['class'], axis=1)\n",
    "Y_train = train_data_set['class']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_train, Y_train, random_state=42)\n",
    "\n",
    "lb = LabelEncoder()\n",
    "Y_train = lb.fit_transform(Y_train)\n",
    "Y_test = lb.transform(Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0f7934",
   "metadata": {},
   "source": [
    "# Correlation matrix between class and num columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "58b6ecae",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = get_preprocessor(columns_num, columns_cat)\n",
    "model = make_pipeline(preprocessor, SGDClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cc7860ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('columntransformer',\n",
       "                 ColumnTransformer(transformers=[('one-hot-encoder',\n",
       "                                                  OneHotEncoder(handle_unknown='ignore'),\n",
       "                                                  ['workclass',\n",
       "                                                   'marital-status',\n",
       "                                                   'occupation', 'relationship',\n",
       "                                                   'race', 'sex',\n",
       "                                                   'native-country']),\n",
       "                                                 ('standard_scaler',\n",
       "                                                  StandardScaler(),\n",
       "                                                  ['age', 'fnlwgt',\n",
       "                                                   'education-num',\n",
       "                                                   'capital-gain',\n",
       "                                                   'capital-loss',\n",
       "                                                   'hours-per-week'])])),\n",
       "                ('sgdclassifier', SGDClassifier())])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "01f6c5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0b8d718a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************* start *************\n",
      "mse  0.14856674856674856\n",
      "acc  0.8514332514332514\n",
      "precision_  0.6348005502063274\n",
      "recall_  0.7105465742879138\n",
      "f1_score_  0.6705412277515438\n",
      "****************************************\n"
     ]
    }
   ],
   "source": [
    "print_scores(y_pred, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "47d5794e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************* start *************\n",
      "mse  0.12596232596232596\n",
      "acc  0.8740376740376741\n",
      "precision_  0.6464924346629987\n",
      "recall_  0.7866108786610879\n",
      "f1_score_  0.7097017742544357\n",
      "****************************************\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "ordinal_encoder = OrdinalEncoder(handle_unknown=\"use_encoded_value\",\n",
    "                                          unknown_value=-1)\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('categorical', ordinal_encoder, columns_cat)],\n",
    "    remainder=\"passthrough\")\n",
    "\n",
    "model = make_pipeline(preprocessor, HistGradientBoostingClassifier())\n",
    "model.fit(X_train, Y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print_scores(y_pred, Y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
