{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c88a671",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-12 02:01:40.478847: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "769da96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "shakespeare_text = None\n",
    "with open('input.txt') as f:\n",
    "    shakespeare_text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c968ddff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of unique characters in the corpus is 65\n",
      "A slice of the unique characters set:\n",
      " ['\\n', ' ', '!', '$', '&', \"'\", ',', '-', '.', '3']\n"
     ]
    }
   ],
   "source": [
    "vocab = sorted(set(shakespeare_text))\n",
    "print ('The number of unique characters in the corpus is', len(vocab))\n",
    "print('A slice of the unique characters set:\\n', vocab[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b805cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "char2idx = {u:i for i, u in enumerate(vocab)}\n",
    "# Make a copy of the unique set elements in NumPy array format for later use in the decoding the predictions\n",
    "idx2char = np.array(vocab)\n",
    "# Vectorize the text with a for loop\n",
    "text_as_int = np.array([char2idx[c] for c in shakespeare_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63d9953a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-12 02:01:44.825259: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create training examples / targets\n",
    "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int) \n",
    "# for i in char_dataset.take(5): \n",
    "#   print(i.numpy())\n",
    "seq_length = 100 # The max. length for single input\n",
    "# examples_per_epoch = len(text)//(seq_length+1) # double-slash for “floor” division\n",
    "sequences = char_dataset.batch(seq_length+1, drop_remainder=True) \n",
    "# for item in sequences.take(5): \n",
    "#   print(repr(''.join(idx2char[item.numpy()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1aa43784",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def split_input_target(chunk):\n",
    "  input_text = chunk[:-1]\n",
    "  target_text = chunk[1:]\n",
    "  return input_text, target_text\n",
    "\n",
    "dataset = sequences.map(split_input_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "43598ceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BatchDataset element_spec=(TensorSpec(shape=(64, 100), dtype=tf.int64, name=None), TensorSpec(shape=(64, 100), dtype=tf.int64, name=None))>\n"
     ]
    }
   ],
   "source": [
    "BUFFER_SIZE = 10000 # TF shuffles the data only within buffers\n",
    "\n",
    "BATCH_SIZE = 64 # Batch size\n",
    "\n",
    "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
    "\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b20311c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Length of the vocabulary in chars\n",
    "vocab_size = len(vocab)\n",
    "# The embedding dimension\n",
    "embedding_dim = 256\n",
    "# Number of RNN units\n",
    "rnn_units = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a2c400c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
    "  model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
    "                              batch_input_shape=[batch_size, None]),\n",
    "    tf.keras.layers.GRU(rnn_units,\n",
    "                        return_sequences=True,\n",
    "                        stateful=True,\n",
    "                        recurrent_initializer='glorot_uniform'),\n",
    "    tf.keras.layers.Dense(vocab_size)\n",
    "  ])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bbb6246f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (64, None, 256)           16640     \n",
      "                                                                 \n",
      " gru (GRU)                   (64, None, 1024)          3938304   \n",
      "                                                                 \n",
      " dense (Dense)               (64, None, 65)            66625     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,021,569\n",
      "Trainable params: 4,021,569\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model(\n",
    "    vocab_size = len(vocab), # no. of unique characters\n",
    "    embedding_dim=embedding_dim, # 256\n",
    "    rnn_units=rnn_units, # 1024\n",
    "    batch_size=BATCH_SIZE)  # 64 for the traning\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "81e39788",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def loss(labels, logits):\n",
    "  return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
    "\n",
    "# example_batch_loss  = loss(target_example_batch, example_batch_predictions)\n",
    "# print(\"Prediction shape: \", example_batch_predictions.shape, \" (batch_size, sequence_length, vocab_size)\")\n",
    "# print(\"scalar_loss:      \", example_batch_loss.numpy().mean())\n",
    "\n",
    "model.compile(optimizer='adam', loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "956a94b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory where the checkpoints will be saved\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "# Name of the checkpoint files\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
    "\n",
    "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "423480d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0 27  5 ... 46 47 51]\n",
      " [ 1 15 59 ... 49  1 41]\n",
      " [39  1 41 ... 10  0 21]\n",
      " ...\n",
      " [52  1 51 ... 59 42  1]\n",
      " [ 1 39 52 ...  1 63 43]\n",
      " [42  1 63 ... 52 42 59]]\n",
      "[[27  5  1 ... 47 51 10]\n",
      " [15 59 54 ...  1 41 46]\n",
      " [ 1 41 59 ...  0 21  1]\n",
      " ...\n",
      " [ 1 51 59 ... 42  1 58]\n",
      " [39 52 42 ... 63 43 39]\n",
      " [ 1 63 53 ... 42 59 56]]\n"
     ]
    }
   ],
   "source": [
    "it = dataset.as_numpy_iterator()\n",
    "d1, d2 = it.next()\n",
    "print(d1)\n",
    "print(d2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8006c240",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "EPOCHS = 30\n",
    "history = model.fit(dataset, \n",
    "                    epochs=EPOCHS, \n",
    "                    callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf16eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, num_generate, temperature, start_string):\n",
    "  input_eval = [char2idx[s] for s in start_string] # string to numbers (vectorizing)\n",
    "  input_eval = tf.expand_dims(input_eval, 0) # dimension expansion\n",
    "  text_generated = [] # Empty string to store our results\n",
    "  model.reset_states() # Clears the hidden states in the RNN\n",
    "\n",
    "  for i in range(num_generate): #Run a loop for number of characters to generate\n",
    "    predictions = model(input_eval) # prediction for single character\n",
    "    predictions = tf.squeeze(predictions, 0) # remove the batch dimension\n",
    "\n",
    "    # using a categorical distribution to predict the character returned by the model\n",
    "    # higher temperature increases the probability of selecting a less likely character\n",
    "    # lower --> more predictable\n",
    "    predictions = predictions / temperature\n",
    "    predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
    "\n",
    "    # The predicted character as the next input to the model\n",
    "    # along with the previous hidden state\n",
    "    # So the model makes the next prediction based on the previous character\n",
    "    input_eval = tf.expand_dims([predicted_id], 0) \n",
    "    # Also devectorize the number and add to the generated text\n",
    "    text_generated.append(idx2char[predicted_id]) \n",
    "\n",
    "  return (start_string + ''.join(text_generated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f78c86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (1, None, 256)            16640     \n",
      "                                                                 \n",
      " gru_3 (GRU)                 (1, None, 1024)           3938304   \n",
      "                                                                 \n",
      " dense_2 (Dense)             (1, None, 65)             66625     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,021,569\n",
      "Trainable params: 4,021,569\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
    "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "model.build(tf.TensorShape([1, None]))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3722591",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROMEO:\n",
      "Come, sir, and I dare not say he: 'fore mestrum lies you into my house;\n",
      "For both offen, ere they give;\n",
      "And, for I am a manner of mercy. And his wonder;\n",
      "Nor what am too much first and what time had made\n",
      "That thou art.\n",
      "\n",
      "AUFIDIUS:\n",
      "You have done enough, nor worse: is't my speech and\n",
      "Willought to my foe till thou do: abother,\n",
      "If he hath lost advanced. O, whilst I dur\n",
      "boy, thou art a tall fellow, and his\n",
      "school'd my wife!\n",
      "\n",
      "ANTONIO:\n",
      "His noble country's reasons of the worst\n",
      "Of Sochaid to be unclar, ev\n"
     ]
    }
   ],
   "source": [
    "generated_text = generate_text(\n",
    "                    model, \n",
    "                    num_generate=500, \n",
    "                    temperature=1, \n",
    "                    start_string=u\"ROMEO\")\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8870ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 1.0)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.DataFrame(history.history).plot() \n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1) # set the vertical range to [0-1] plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96335fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = keras.preprocessing.text.Tokenizer(char_level=True)\n",
    "tokenizer.fit_on_texts([shakespeare_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2ee733",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[20, 6, 9, 8, 3]], ['f i r s t'], [[1]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.texts_to_sequences([\"First\"]), tokenizer.sequences_to_texts([[20, 6, 9, 8, 3]]), tokenizer.texts_to_sequences([\" \"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a926ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39, 1)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_id = len(tokenizer.word_index) # number of distinct characters\n",
    "dataset_size = tokenizer.document_count # total number of characters\n",
    "\n",
    "max_id, dataset_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684aee94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode the full text so each character is represented by its ID \n",
    "# (we subtract 1 to get IDs from 0 to 38, rather than from 1 to 39)\n",
    "\n",
    "[encoded] = np.array(tokenizer.texts_to_sequences([shakespeare_text])) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff78663",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = dataset_size * 90 // 100\n",
    "dataset = tf.data.Dataset.from_tensor_slices(encoded[:train_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a08c7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 100\n",
    "window_length = n_steps + 1 # target = input shifted 1 character ahead \n",
    "dataset = dataset.window(window_length, shift=1, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74bfa15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<FlatMapDataset element_spec=TensorSpec(shape=(None,), dtype=tf.int64, name=None)>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dataset.flat_map(lambda window: window.batch(window_length))\n",
    "dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa1f47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "dataset = dataset.shuffle(10000).batch(batch_size)\n",
    "dataset = dataset.map(lambda windows: (windows[:, :-1], windows[:, 1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e9c9db65",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'BatchDataset' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m dataset[:\u001b[39m1\u001b[39;49m, :\u001b[39m1\u001b[39;49m]\n",
      "\u001b[0;31mTypeError\u001b[0m: 'BatchDataset' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "dataset[:1, :1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f632d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.GRU(128, return_sequences=True, input_shape=[None, max_id], dropout=0.2, recurrent_dropout=0.2),\n",
    "    keras.layers.GRU(128, return_sequences=True, dropout=0.2, recurrent_dropout=0.2),\n",
    "    keras.layers.TimeDistributed(keras.layers.Dense(max_id, activation=\"softmax\"))])\n",
    "    \n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013c6b2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "WARNING:tensorflow:Model was constructed with shape (None, None, 39) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, 39), dtype=tf.float32, name='gru_input'), name='gru_input', description=\"created by layer 'gru_input'\"), but it was called on an input with incompatible shape (None, None).\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/Users/piyushr/workspace/personal/venv/lib/python3.9/site-packages/keras/engine/training.py\", line 1249, in train_function  *\n        return step_function(self, iterator)\n    File \"/Users/piyushr/workspace/personal/venv/lib/python3.9/site-packages/keras/engine/training.py\", line 1233, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/piyushr/workspace/personal/venv/lib/python3.9/site-packages/keras/engine/training.py\", line 1222, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Users/piyushr/workspace/personal/venv/lib/python3.9/site-packages/keras/engine/training.py\", line 1023, in train_step\n        y_pred = self(x, training=True)\n    File \"/Users/piyushr/workspace/personal/venv/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/Users/piyushr/workspace/personal/venv/lib/python3.9/site-packages/keras/engine/input_spec.py\", line 232, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer 'sequential' (type Sequential).\n    \n    Input 0 of layer \"gru\" is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: (None, None)\n    \n    Call arguments received by layer 'sequential' (type Sequential):\n      • inputs=tf.Tensor(shape=(None, None), dtype=int64)\n      • training=True\n      • mask=None\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(dataset, epochs\u001b[39m=\u001b[39;49m\u001b[39m20\u001b[39;49m)\n",
      "File \u001b[0;32m~/workspace/personal/venv/lib/python3.9/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/var/folders/j6/vt_gmt8x1n74q_9nccxjmp5w0000gp/T/__autograph_generated_file5d0yv10s.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(step_function), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), ag__\u001b[39m.\u001b[39mld(iterator)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/Users/piyushr/workspace/personal/venv/lib/python3.9/site-packages/keras/engine/training.py\", line 1249, in train_function  *\n        return step_function(self, iterator)\n    File \"/Users/piyushr/workspace/personal/venv/lib/python3.9/site-packages/keras/engine/training.py\", line 1233, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/piyushr/workspace/personal/venv/lib/python3.9/site-packages/keras/engine/training.py\", line 1222, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Users/piyushr/workspace/personal/venv/lib/python3.9/site-packages/keras/engine/training.py\", line 1023, in train_step\n        y_pred = self(x, training=True)\n    File \"/Users/piyushr/workspace/personal/venv/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/Users/piyushr/workspace/personal/venv/lib/python3.9/site-packages/keras/engine/input_spec.py\", line 232, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer 'sequential' (type Sequential).\n    \n    Input 0 of layer \"gru\" is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: (None, None)\n    \n    Call arguments received by layer 'sequential' (type Sequential):\n      • inputs=tf.Tensor(shape=(None, None), dtype=int64)\n      • training=True\n      • mask=None\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(dataset, epochs=20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "3ccfa0cc7987480c27b9ca0f59c3a2d59999bd31ea927a6b1a2cfba7d1e11b95"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
