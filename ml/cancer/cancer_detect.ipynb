{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f1e4c647",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from pandas.plotting import scatter_matrix\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, OrdinalEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import seaborn as sb\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a2ed2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_directory = '~/workspace/personal/datasets/cancer'\n",
    "\n",
    "columns = ['Sample code number', 'Clump Thickness',\n",
    "'Uniformity of Cell Size',\n",
    "'Uniformity of Cell Shape',\n",
    "'Marginal Adhesion',\n",
    "'Single Epithelial Cell Size',\n",
    "'Bare Nuclei',\n",
    "'Bland Chromatin',\n",
    "'Normal Nucleoli',\n",
    "'Mitoses',\n",
    "'Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3784cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def using_model(model, scoring, cv):\n",
    "    print(\"****************** {} ******************\".format(model))\n",
    "    if scoring is not None:\n",
    "        scores_ = cross_val_score(model, X_train, y_train, scoring=scoring, cv=cv)\n",
    "        print(\"scoring={} cv={}\".format(scoring, cv), scores_.mean(), scores_.std())\n",
    "    model.fit(X_train, y_train)\n",
    "    y_predict = model.predict(X_test)\n",
    "    print(\"accuracy_score=\", accuracy_score(y_test, y_predict))\n",
    "    print(\"precision_score=\", precision_score(y_test, y_predict, average='micro'))\n",
    "    print(\"recall_score=\", recall_score(y_test, y_predict, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61248bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_csv_data(directory, file_name, names=None, header=None, skiprows=0, skipinitialspace=True):\n",
    "    return pd.read_csv(os.path.join(directory, file_name), names=names, header=header, skiprows=skiprows, skipinitialspace=skipinitialspace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0252d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix(model, X_train, Y_train):\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "\n",
    "    y_scores_ = cross_val_predict(model, X_train, Y_train, cv=3, method=\"decision_function\")\n",
    "    model.fit(X_train, Y_train)\n",
    "    Y_predict = model.predict(X_train)\n",
    "    conf_mx = confusion_matrix(Y_train, Y_predict)\n",
    "    plt.matshow(conf_mx, cmap=plt.cm.gray)\n",
    "#     print(\"accuracy_score=\", accuracy_score(Y_train, Y_predict))\n",
    "#     print(\"precision_score=\", precision_score(Y_train, Y_predict))\n",
    "#     print(\"recall_score=\", recall_score(Y_train, Y_predict))\n",
    "    print(lb.classes_)\n",
    "    print(lb.transform(lb.classes_))\n",
    "    print(conf_mx)\n",
    "    row_sums = conf_mx.sum(axis=1, keepdims=True)\n",
    "    norm_conf_mx = conf_mx / row_sums\n",
    "\n",
    "    np.fill_diagonal(norm_conf_mx, 0)\n",
    "    plt.matshow(norm_conf_mx, cmap=plt.cm.gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f01560d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_csv_data(base_directory, 'breast-cancer-wisconsin.data', names=columns)\n",
    "df = df.drop('Sample code number', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7787a59e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Clump Thickness</th>\n",
       "      <th>Uniformity of Cell Size</th>\n",
       "      <th>Uniformity of Cell Shape</th>\n",
       "      <th>Marginal Adhesion</th>\n",
       "      <th>Single Epithelial Cell Size</th>\n",
       "      <th>Bland Chromatin</th>\n",
       "      <th>Normal Nucleoli</th>\n",
       "      <th>Mitoses</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>699.000000</td>\n",
       "      <td>699.000000</td>\n",
       "      <td>699.000000</td>\n",
       "      <td>699.000000</td>\n",
       "      <td>699.000000</td>\n",
       "      <td>699.000000</td>\n",
       "      <td>699.000000</td>\n",
       "      <td>699.000000</td>\n",
       "      <td>699.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.417740</td>\n",
       "      <td>3.134478</td>\n",
       "      <td>3.207439</td>\n",
       "      <td>2.806867</td>\n",
       "      <td>3.216023</td>\n",
       "      <td>3.437768</td>\n",
       "      <td>2.866953</td>\n",
       "      <td>1.589413</td>\n",
       "      <td>2.689557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.815741</td>\n",
       "      <td>3.051459</td>\n",
       "      <td>2.971913</td>\n",
       "      <td>2.855379</td>\n",
       "      <td>2.214300</td>\n",
       "      <td>2.438364</td>\n",
       "      <td>3.053634</td>\n",
       "      <td>1.715078</td>\n",
       "      <td>0.951273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Clump Thickness  Uniformity of Cell Size  Uniformity of Cell Shape  \\\n",
       "count       699.000000               699.000000                699.000000   \n",
       "mean          4.417740                 3.134478                  3.207439   \n",
       "std           2.815741                 3.051459                  2.971913   \n",
       "min           1.000000                 1.000000                  1.000000   \n",
       "25%           2.000000                 1.000000                  1.000000   \n",
       "50%           4.000000                 1.000000                  1.000000   \n",
       "75%           6.000000                 5.000000                  5.000000   \n",
       "max          10.000000                10.000000                 10.000000   \n",
       "\n",
       "       Marginal Adhesion  Single Epithelial Cell Size  Bland Chromatin  \\\n",
       "count         699.000000                   699.000000       699.000000   \n",
       "mean            2.806867                     3.216023         3.437768   \n",
       "std             2.855379                     2.214300         2.438364   \n",
       "min             1.000000                     1.000000         1.000000   \n",
       "25%             1.000000                     2.000000         2.000000   \n",
       "50%             1.000000                     2.000000         3.000000   \n",
       "75%             4.000000                     4.000000         5.000000   \n",
       "max            10.000000                    10.000000        10.000000   \n",
       "\n",
       "       Normal Nucleoli     Mitoses       Class  \n",
       "count       699.000000  699.000000  699.000000  \n",
       "mean          2.866953    1.589413    2.689557  \n",
       "std           3.053634    1.715078    0.951273  \n",
       "min           1.000000    1.000000    2.000000  \n",
       "25%           1.000000    1.000000    2.000000  \n",
       "50%           1.000000    1.000000    2.000000  \n",
       "75%           4.000000    1.000000    4.000000  \n",
       "max          10.000000   10.000000    4.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59a691d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 699 entries, 0 to 698\n",
      "Data columns (total 10 columns):\n",
      " #   Column                       Non-Null Count  Dtype \n",
      "---  ------                       --------------  ----- \n",
      " 0   Clump Thickness              699 non-null    int64 \n",
      " 1   Uniformity of Cell Size      699 non-null    int64 \n",
      " 2   Uniformity of Cell Shape     699 non-null    int64 \n",
      " 3   Marginal Adhesion            699 non-null    int64 \n",
      " 4   Single Epithelial Cell Size  699 non-null    int64 \n",
      " 5   Bare Nuclei                  683 non-null    object\n",
      " 6   Bland Chromatin              699 non-null    int64 \n",
      " 7   Normal Nucleoli              699 non-null    int64 \n",
      " 8   Mitoses                      699 non-null    int64 \n",
      " 9   Class                        699 non-null    int64 \n",
      "dtypes: int64(9), object(1)\n",
      "memory usage: 54.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df.loc[df['Bare Nuclei'] == '?', 'Bare Nuclei'] = np.nan\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a76d822d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42) \n",
    "\n",
    "for train_index, test_index in split.split(\n",
    "    df.drop('Class', axis=1),\n",
    "    df['Class']):\n",
    "        train_set = df.loc[train_index]\n",
    "        test_set = df.loc[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec8d9de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_set.drop('Class', axis=1)\n",
    "y_train = train_set['Class']\n",
    "\n",
    "X_test = test_set.drop('Class', axis=1)\n",
    "y_test = test_set['Class']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "20304f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pipeline = Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy=\"median\")),\n",
    "            ('std_scaler', StandardScaler()),\n",
    "            #('minmax_scaler', MinMaxScaler()),\n",
    "        ])\n",
    "\n",
    "X_train = num_pipeline.fit_transform(X_train)\n",
    "X_test = num_pipeline.fit_transform(X_test)\n",
    "\n",
    "lb = LabelEncoder()\n",
    "y_train = lb.fit_transform(y_train)\n",
    "y_test = lb.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0949d53e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************** LogisticRegression(max_iter=500, multi_class='multinomial') ******************\n",
      "accuracy_score= 0.9571428571428572\n",
      "precision_score= 0.9571428571428572\n",
      "recall_score= 0.9571428571428572\n"
     ]
    }
   ],
   "source": [
    "using_model(LogisticRegression(max_iter=500, multi_class=\"multinomial\"), None, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1d20c5b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************** SGDClassifier() ******************\n",
      "accuracy_score= 0.9642857142857143\n",
      "precision_score= 0.9642857142857143\n",
      "recall_score= 0.9642857142857143\n"
     ]
    }
   ],
   "source": [
    "using_model(SGDClassifier(), None, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e1974265",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************** SVC() ******************\n",
      "accuracy_score= 0.9571428571428572\n",
      "precision_score= 0.9571428571428572\n",
      "recall_score= 0.9571428571428572\n"
     ]
    }
   ],
   "source": [
    "using_model(SVC(), None, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dcfd0428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************** RandomForestClassifier() ******************\n",
      "accuracy_score= 0.9571428571428572\n",
      "precision_score= 0.9571428571428572\n",
      "recall_score= 0.9571428571428572\n"
     ]
    }
   ],
   "source": [
    "using_model(RandomForestClassifier(), None, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4b4d033e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************** DecisionTreeClassifier() ******************\n",
      "accuracy_score= 0.9285714285714286\n",
      "precision_score= 0.9285714285714286\n",
      "recall_score= 0.9285714285714286\n"
     ]
    }
   ],
   "source": [
    "using_model(DecisionTreeClassifier(), None, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9a4231df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************** AdaBoostClassifier(estimator=DecisionTreeClassifier(max_depth=15),\n",
      "                   learning_rate=0.3, n_estimators=225) ******************\n",
      "accuracy_score= 0.9214285714285714\n",
      "precision_score= 0.9214285714285714\n",
      "recall_score= 0.9214285714285714\n"
     ]
    }
   ],
   "source": [
    "a = AdaBoostClassifier(DecisionTreeClassifier(max_depth=15), n_estimators=225, \n",
    "                       algorithm=\"SAMME.R\", learning_rate=0.3)\n",
    "using_model(a, None, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b8dfb43f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************** AdaBoostClassifier(estimator=LogisticRegression(max_iter=500,\n",
      "                                                multi_class='multinomial'),\n",
      "                   learning_rate=0.3, n_estimators=225) ******************\n",
      "accuracy_score= 0.9571428571428572\n",
      "precision_score= 0.9571428571428572\n",
      "recall_score= 0.9571428571428572\n"
     ]
    }
   ],
   "source": [
    "a1 = AdaBoostClassifier(LogisticRegression(max_iter=500, multi_class=\"multinomial\"),\n",
    "                        n_estimators=225, algorithm=\"SAMME.R\", learning_rate=0.3)\n",
    "using_model(a1, None, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7bf0765c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************** OneVsRestClassifier(estimator=SVC()) ******************\n",
      "accuracy_score= 0.9571428571428572\n",
      "precision_score= 0.9571428571428572\n",
      "recall_score= 0.9571428571428572\n"
     ]
    }
   ],
   "source": [
    "ovr = OneVsRestClassifier(SVC())\n",
    "\n",
    "using_model(ovr, None, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c3e50ba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_features': 2, 'n_estimators': 120}\n",
      "RandomForestClassifier(max_features=2, n_estimators=120)\n"
     ]
    }
   ],
   "source": [
    "param_grid = [\n",
    "        {'n_estimators': [50, 60, 70, 71, 75, 100, 120, 150], 'max_features': [2, 4, 6, 8]},\n",
    "        {'bootstrap': [False], 'n_estimators': [3, 10], 'max_features': [2, 3, 4]},\n",
    "    ]\n",
    "\n",
    "\n",
    "# m = RandomForestRegressor()\n",
    "# m.fit(X_train, y_train)\n",
    "    \n",
    "grid_search = GridSearchCV(RandomForestClassifier(), param_grid, cv=10)\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(grid_search.best_params_)\n",
    "print(grid_search.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "72b80bcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************** RandomForestClassifier(max_features=2, n_estimators=120) ******************\n",
      "accuracy_score= 0.9642857142857143\n",
      "precision_score= 0.9642857142857143\n",
      "recall_score= 0.9642857142857143\n"
     ]
    }
   ],
   "source": [
    "using_model(RandomForestClassifier(max_features=2, n_estimators=120), None, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2b5fbd15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_iter': 1200, 'penalty': 'l1'}\n",
      "SGDClassifier(max_iter=1200, penalty='l1')\n",
      "****************** SGDClassifier(max_iter=1300, penalty='elasticnet') ******************\n",
      "accuracy_score= 0.9571428571428572\n",
      "precision_score= 0.9571428571428572\n",
      "recall_score= 0.9571428571428572\n"
     ]
    }
   ],
   "source": [
    "param_grid = [\n",
    "        {'max_iter': [500, 600, 1000, 1200, 1300, 1310, 1350, 1400],\n",
    "         'penalty': ['l2', 'l1', 'elasticnet', None]}\n",
    "    ]\n",
    "\n",
    "grid_search = GridSearchCV(SGDClassifier(), param_grid, cv=10)\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(grid_search.best_params_)\n",
    "print(grid_search.best_estimator_)\n",
    "\n",
    "using_model(SGDClassifier(max_iter=1300, penalty='elasticnet'), None, 10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
